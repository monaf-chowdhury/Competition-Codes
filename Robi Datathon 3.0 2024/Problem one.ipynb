{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "In the realm of Neverland, where enchantment stretched far and wide, there lived a kind-hearted cattleman named Grassland Gus. His farm, Moo Meadows, was the sole source of the most delicious meat and milk in the kingdom. The people of Neverland would come from far and wide to procure these treasures.\n",
    "\n",
    "Some procured these items directly from the farm at wholesale rates, while others obtained them from nearby groceries at retail prices. Fresh items were available at a premium, while frozen ones were sold at standard prices.\n",
    "\n",
    "Gus packaged his dairy and meat in Enchanted Boxes. Each box held a different combination of meat and milk, and depending on their quality, some boxes were more valuable than others.\n",
    "\n",
    "To purchase these magical boxes, the denizens of Neverland used Wishing Coins, which are tokens earned through acts of kindness. Every buyer had their own unique Magic Key, which kept track of all their purchases.\n",
    "\n",
    "All exchanges of the kingdom are logged in the Enchanted Scroll, details of which are given in the file purchase.csv. The file contains records of purchases made over the last five months, including the date of purchase, the customer's magic key, the box ID purchased and purchase unit. Denizens select boxes to purchase from a list written on parchment. The dataset Boxes.csv enumerates all available boxes, including the box ID, product quality, delivery option, quantity of milk (cauldron), quantity of meat (stones) and box unit price.\n",
    "\n",
    "There is no specific train.csv for this contest. Only **\"purchase.csv\"** and **\"boxes.csv\"** are given. You have to do everything from these two files.\n",
    "\n",
    "**\"problem 1.csv\"** is given for you to predict, **\"sample submission 1.csv\"** is also there to help you about the submission template.\n",
    "\n",
    "**You need to predict which of the Magic Keys given in “problem 1.csv” will buy milk and/or meat in the first 15 days of March-2019. Put Y in the purchase column if the Magic Keys will purchase and N if the Magic Keys will not make a purchase. Prepare and submit as submission.csv following the the template (sample submission 1.csv).**\n",
    "\n",
    "------- \n",
    "Evaluation\n",
    "The evaluation metric for this problem is Accuracy. Accuracy is a fundamental evaluation metric in machine learning, particularly for classification tasks. It measures the proportion of correctly predicted instances out of the total instances in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem One Standing\n",
    "------\n",
    "\n",
    "**6th Place out of 240**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic testing\n",
    "This code is to test out the generic theory or eda for the problem datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "purchase = pd.read_csv(\"Problem 1/purchase.csv\")\n",
    "box = pd.read_csv(\"Problem 1/boxes.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping ducplicates, nan values and impossible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PURCHASE_DATE    2455723\n",
       "MAGIC_KEY        2455723\n",
       "BOX_ID           2455723\n",
       "BOX_COUNT        2455723\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase = purchase.dropna().drop_duplicates() # Drop NaN values and duplicates\n",
    "positive_box_count_mask = purchase['BOX_COUNT'] >= 0\n",
    "purchase = purchase[positive_box_count_mask]\n",
    "purchase['PURCHASE_DATE'] = pd.to_datetime(purchase['PURCHASE_DATE'], format='%d/%m/%Y')\n",
    "purchase = purchase.sort_values(by='PURCHASE_DATE') # Sort purchase data by purchase date in ascending order\n",
    "purchase.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. New dynamic method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate_avg_time_between_purchases and feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_time_between_purchases(group):\n",
    "    if len(group) > 1:\n",
    "        return np.mean(group['PURCHASE_DATE'].diff().dt.days)\n",
    "    else:\n",
    "        return 150\n",
    "    \n",
    "def feature_extraction(purchase,grouped_df,box):\n",
    "    # Task 1: Calculate the frequency of purchases for each Magic Key within specific time intervals (bi-weekly and monthly)\n",
    "    print('1/6 Extracting Bi-Weekly and Monthly Purchase Count...')\n",
    "    biweekly_purchase_count = purchase.groupby(['MAGIC_KEY', pd.Grouper(key='PURCHASE_DATE', freq='2W')]).size().unstack(fill_value=0)\n",
    "    monthly_purchase_count = purchase.groupby(['MAGIC_KEY', pd.Grouper(key='PURCHASE_DATE', freq='ME')]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Task 2: Calculate the average time between purchases for each Magic Key\n",
    "    print('2/6 Extracting Average Time between purchase...')\n",
    "    avg_time_between_purchases = grouped_df.apply(calculate_avg_time_between_purchases)\n",
    "\n",
    "    # Task 3 days_since_last_purchase\n",
    "    print('3/6 Extracting Days since last purchase...')\n",
    "    last_purchase_date = grouped_df['PURCHASE_DATE'].max()\n",
    "    days_since_last_purchase = (purchase['PURCHASE_DATE'].max() - last_purchase_date).dt.days.copy()\n",
    "    \n",
    "    # Task 4 purchase_count and total_spent\n",
    "    print('4/6 Extracting purchase_count and total_spent...')\n",
    "    merged_df = pd.merge(purchase, box, on='BOX_ID') \n",
    "    merged_df['SPENT'] = merged_df['BOX_COUNT'] * merged_df['UNIT_PRICE']\n",
    "    grouped_df = merged_df.groupby('MAGIC_KEY') \n",
    "    purchase_count = grouped_df.size().rename('Purchase_Count') \n",
    "    total_spent = grouped_df['SPENT'].sum().rename('Total_Spent')\n",
    "    # total_spent = grouped_df['UNIT_PRICE'].sum().rename('Total_Spent')\n",
    "\n",
    "    # Task 5  total_milk_quantity & total_meat_quantity\n",
    "    print('5/6 Extracting total_milk_quantity & total_meat_quantity...')\n",
    "    total_milk_quantity = grouped_df['MILK'].sum().rename('Total_Milk_Quantity')\n",
    "    total_meat_quantity = grouped_df['MEAT'].sum().rename('Total_Meat_Quantity')\n",
    "    \n",
    "    # Task 6 num_purchases_first_15_days and num_purchases_last_15_days\n",
    "    print('6/6 Extracting num_purchases_first_15_days and num_purchases_last_15_days...')\n",
    "    first_15_days_purchase = merged_df[merged_df['PURCHASE_DATE'].dt.day <= 15]\n",
    "    num_purchases_first_15_days = first_15_days_purchase.groupby(['MAGIC_KEY', first_15_days_purchase['PURCHASE_DATE'].dt.month]).size().groupby('MAGIC_KEY').sum()\n",
    "    last_15_days_purchase = merged_df[merged_df['PURCHASE_DATE'].dt.day > 15]\n",
    "    num_purchases_last_15_days = last_15_days_purchase.groupby(['MAGIC_KEY', last_15_days_purchase['PURCHASE_DATE'].dt.month]).size().groupby('MAGIC_KEY').sum()\n",
    "\n",
    "\n",
    "\n",
    "    # Combine all features into a DataFrame\n",
    "    features = pd.DataFrame({\n",
    "        'Biweekly_Purchase_Count': biweekly_purchase_count.mean(axis=1),\n",
    "        'Monthly_Purchase_Count': monthly_purchase_count.mean(axis=1),\n",
    "        'Avg_Time_Between_Purchases': avg_time_between_purchases,\n",
    "        'Days_Since_Last_Purchase': days_since_last_purchase\n",
    "    })\n",
    "    purchase_history_features = pd.concat([purchase_count, total_spent], axis=1) # Create a new DataFrame with purchase history features\n",
    "    features = features.join(purchase_history_features, how='left')\n",
    "    box_features_df = pd.concat([total_milk_quantity, total_meat_quantity], axis=1)\n",
    "    features = features.join(box_features_df, how='left')\n",
    "    features['Num_Purchases_First_15_Days'] = num_purchases_first_15_days\n",
    "    features['Num_Purchases_Last_15_Days'] = num_purchases_last_15_days\n",
    "    features = features.fillna(0)\n",
    "    return features\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set time boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/6 Extracting Bi-Weekly and Monthly Purchase Count...\n",
      "2/6 Extracting Average Time between purchase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monaf\\AppData\\Local\\Temp\\ipykernel_20948\\4279281223.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  avg_time_between_purchases = grouped_df.apply(calculate_avg_time_between_purchases)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/6 Extracting Days since last purchase...\n",
      "4/6 Extracting purchase_count and total_spent...\n",
      "5/6 Extracting total_milk_quantity & total_meat_quantity...\n",
      "6/6 Extracting num_purchases_first_15_days and num_purchases_last_15_days...\n"
     ]
    }
   ],
   "source": [
    "purchase_oct_nov = purchase[(purchase['PURCHASE_DATE'].dt.year == 2018) &\n",
    "                                    ((purchase['PURCHASE_DATE'].dt.month == 10) |\n",
    "                                     (purchase['PURCHASE_DATE'].dt.month == 11))]\n",
    "grouped_df_oct_nov = purchase_oct_nov.groupby('MAGIC_KEY') # Group by MAGIC_KEY\n",
    "features = feature_extraction(purchase_oct_nov,grouped_df_oct_nov,box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "def Labelling_features(features, purchase, year, month):\n",
    "    # scaler = StandardScaler()\n",
    "    # features_scaled = scaler.fit_transform(features)\n",
    "    purchase_half = purchase[(purchase['PURCHASE_DATE'].dt.year == year) &  \n",
    "                                    (purchase['PURCHASE_DATE'].dt.month == month) &   # Filter by month\n",
    "                                    (purchase['PURCHASE_DATE'].dt.day <= 15)] \n",
    "    \n",
    "    half_keys = purchase_half['MAGIC_KEY'].unique()\n",
    "    features['labels'] = 0\n",
    "    features.loc[features.index.isin(half_keys), 'labels'] = 1\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Labelling_features(features,purchase, 2018,12) # for december of 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def define_model(n_input, n_hidden_layer, n_unit_per_layer,dropout_rate=0.2, l2_penalty=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_unit_per_layer, input_shape=(n_input,), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(l2_penalty)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model train on OCT-NOV data. label DEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda_2024\\envs\\competition\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7940 - loss: 0.7934\n",
      "Epoch 2/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8174 - loss: 0.4272\n",
      "Epoch 3/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.4246\n",
      "Epoch 4/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.4213\n",
      "Epoch 5/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8190 - loss: 0.4190\n",
      "Epoch 6/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4189\n",
      "Epoch 7/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.4185\n",
      "Epoch 8/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.4175\n",
      "Epoch 9/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.4185\n",
      "Epoch 10/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.4185\n",
      "Epoch 11/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8186 - loss: 0.4171\n",
      "Epoch 12/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8189 - loss: 0.4161\n",
      "Epoch 13/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.4161\n",
      "Epoch 14/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.4154\n",
      "Epoch 15/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.4153\n",
      "Epoch 16/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8186 - loss: 0.4167\n",
      "Epoch 17/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.4190\n",
      "Epoch 18/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8168 - loss: 0.4168\n",
      "Epoch 19/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4167\n",
      "Epoch 20/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8188 - loss: 0.4152\n",
      "Epoch 21/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.4167\n",
      "Epoch 22/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.4141\n",
      "Epoch 23/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8177 - loss: 0.4163\n",
      "Epoch 24/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.4174\n",
      "Epoch 25/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.4168\n",
      "Epoch 26/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4174\n",
      "Epoch 27/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8168 - loss: 0.4179\n",
      "Epoch 28/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8175 - loss: 0.4177\n",
      "Epoch 29/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.4168\n",
      "Epoch 30/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.4174\n",
      "Epoch 31/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4156\n",
      "Epoch 32/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8186 - loss: 0.4165\n",
      "Epoch 33/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.4161\n",
      "Epoch 34/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.4165\n",
      "Epoch 35/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8188 - loss: 0.4169\n",
      "Epoch 36/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8177 - loss: 0.4177\n",
      "Epoch 37/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.4157\n",
      "Epoch 38/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8175 - loss: 0.4172\n",
      "Epoch 39/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.4173\n",
      "Epoch 40/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.4159\n",
      "Epoch 41/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4159\n",
      "Epoch 42/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4153\n",
      "Epoch 43/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8183 - loss: 0.4153\n",
      "Epoch 44/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4164\n",
      "Epoch 45/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8189 - loss: 0.4150\n",
      "Epoch 46/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8183 - loss: 0.4164\n",
      "Epoch 47/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.4169\n",
      "Epoch 48/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8186 - loss: 0.4162\n",
      "Epoch 49/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4158\n",
      "Epoch 50/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.4156\n",
      "\u001b[1m4018/4018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 784us/step - accuracy: 0.8118 - loss: 0.4253\n",
      "Test Loss: 0.4253541827201843\n",
      "Test Accuracy: 0.8124460577964783\n"
     ]
    }
   ],
   "source": [
    "labels = features['labels'].to_numpy()\n",
    "features_pure = (features.drop(columns=['labels'])).to_numpy()\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_pure)\n",
    "num_node = 50\n",
    "\n",
    "model_oct_nov = define_model(features_scaled.shape[1], 1, num_node)\n",
    "model_oct_nov.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), metrics=['accuracy'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.2, random_state=42)\n",
    "hist_oct_nov = model_oct_nov.fit(X_train, y_train, epochs=50, batch_size=2048)\n",
    "test_loss, test_accuracy = model_oct_nov.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "model_oct_nov_weights = model_oct_nov.get_weights()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model train on OCT-NOV-DEC Label Jan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/6 Extracting Bi-Weekly and Monthly Purchase Count...\n",
      "2/6 Extracting Average Time between purchase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monaf\\AppData\\Local\\Temp\\ipykernel_20948\\4279281223.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  avg_time_between_purchases = grouped_df.apply(calculate_avg_time_between_purchases)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/6 Extracting Days since last purchase...\n",
      "4/6 Extracting purchase_count and total_spent...\n",
      "5/6 Extracting total_milk_quantity & total_meat_quantity...\n",
      "6/6 Extracting num_purchases_first_15_days and num_purchases_last_15_days...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda_2024\\envs\\competition\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4021\n",
      "Epoch 2/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8360 - loss: 0.3948\n",
      "Epoch 3/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.3949\n",
      "Epoch 4/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.3948\n",
      "Epoch 5/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.3952\n",
      "Epoch 6/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8360 - loss: 0.3939\n",
      "Epoch 7/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.3947\n",
      "Epoch 8/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.3930\n",
      "Epoch 9/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.3942\n",
      "Epoch 10/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8366 - loss: 0.3931\n",
      "Epoch 11/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.3933\n",
      "Epoch 12/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8360 - loss: 0.3935\n",
      "Epoch 13/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8366 - loss: 0.3935\n",
      "Epoch 14/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3939\n",
      "Epoch 15/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3937\n",
      "Epoch 16/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.3941\n",
      "Epoch 17/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.3927\n",
      "Epoch 18/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3932\n",
      "Epoch 19/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3935\n",
      "Epoch 20/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8360 - loss: 0.3932\n",
      "Epoch 21/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.3934\n",
      "Epoch 22/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.3930\n",
      "Epoch 23/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.3924\n",
      "Epoch 24/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8358 - loss: 0.3935\n",
      "Epoch 25/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3938\n",
      "Epoch 26/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8353 - loss: 0.3939\n",
      "Epoch 27/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3933\n",
      "Epoch 28/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.3927\n",
      "Epoch 29/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.3933\n",
      "Epoch 30/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.3935\n",
      "Epoch 31/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.3935\n",
      "Epoch 32/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.3932\n",
      "Epoch 33/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.3936\n",
      "Epoch 34/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8355 - loss: 0.3931\n",
      "Epoch 35/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.3935\n",
      "Epoch 36/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8358 - loss: 0.3940\n",
      "Epoch 37/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8368 - loss: 0.3920\n",
      "Epoch 38/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8358 - loss: 0.3926\n",
      "Epoch 39/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.3919\n",
      "Epoch 40/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.3932\n",
      "Epoch 41/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3925\n",
      "Epoch 42/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.3934\n",
      "Epoch 43/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.3924\n",
      "Epoch 44/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8373 - loss: 0.3911\n",
      "Epoch 45/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.3932\n",
      "Epoch 46/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.3924\n",
      "Epoch 47/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.3918\n",
      "Epoch 48/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.3926\n",
      "Epoch 49/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.3927\n",
      "Epoch 50/50\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.3917\n",
      "\u001b[1m5269/5269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 698us/step - accuracy: 0.8375 - loss: 0.3864\n",
      "Test Loss: 0.38868066668510437\n",
      "Test Accuracy: 0.8365026712417603\n"
     ]
    }
   ],
   "source": [
    "# Time boundary, OCT, Nov, Dec\n",
    "purchase_oct_nov_dec = purchase[(purchase['PURCHASE_DATE'].dt.year == 2018) &\n",
    "                                    ((purchase['PURCHASE_DATE'].dt.month == 10) |\n",
    "                                     (purchase['PURCHASE_DATE'].dt.month == 11) |\n",
    "                                     (purchase['PURCHASE_DATE'].dt.month == 12))]\n",
    "grouped_df_oct_nov_dec = purchase_oct_nov_dec.groupby('MAGIC_KEY') # Group by MAGIC_KEY\n",
    "features = feature_extraction(purchase_oct_nov_dec,grouped_df_oct_nov_dec,box)\n",
    "\n",
    "# Labelling \n",
    "features = Labelling_features(features,purchase, 2019, 1) # for January of 2019\n",
    "\n",
    "#defining elimentary things\n",
    "labels = features['labels'].to_numpy()\n",
    "features_pure = (features.drop(columns=['labels'])).to_numpy()\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_pure)\n",
    "num_node = 50\n",
    "\n",
    "# Model defining and setting previous weights\n",
    "model_oct_nov_dec = define_model(features_scaled.shape[1], 1, num_node)\n",
    "model_oct_nov_dec.set_weights(model_oct_nov_weights)\n",
    "model_oct_nov_dec.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.2, random_state=42)\n",
    "hist_oct_nov_dec = model_oct_nov_dec.fit(X_train, y_train, epochs=50, batch_size=2048)\n",
    "test_loss, test_accuracy = model_oct_nov_dec.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "model_oct_nov_dec_weights = model_oct_nov_dec.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model train on OCT-NOV-DEC-Jan Label Feb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/6 Extracting Bi-Weekly and Monthly Purchase Count...\n",
      "2/6 Extracting Average Time between purchase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monaf\\AppData\\Local\\Temp\\ipykernel_20948\\4279281223.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  avg_time_between_purchases = grouped_df.apply(calculate_avg_time_between_purchases)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/6 Extracting Days since last purchase...\n",
      "4/6 Extracting purchase_count and total_spent...\n",
      "5/6 Extracting total_milk_quantity & total_meat_quantity...\n",
      "6/6 Extracting num_purchases_first_15_days and num_purchases_last_15_days...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda_2024\\envs\\competition\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.3809\n",
      "Epoch 2/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3787\n",
      "Epoch 3/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8433 - loss: 0.3789\n",
      "Epoch 4/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3790\n",
      "Epoch 5/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3797\n",
      "Epoch 6/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3787\n",
      "Epoch 7/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.3789\n",
      "Epoch 8/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3793\n",
      "Epoch 9/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3795\n",
      "Epoch 10/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8437 - loss: 0.3783\n",
      "Epoch 11/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3793\n",
      "Epoch 12/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3789\n",
      "Epoch 13/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3785\n",
      "Epoch 14/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3789\n",
      "Epoch 15/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3791\n",
      "Epoch 16/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3778\n",
      "Epoch 17/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.3785\n",
      "Epoch 18/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8444 - loss: 0.3768\n",
      "Epoch 19/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3792\n",
      "Epoch 20/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.3787\n",
      "Epoch 21/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.3789\n",
      "Epoch 22/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3779\n",
      "Epoch 23/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3783\n",
      "Epoch 24/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.3784\n",
      "Epoch 25/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3784\n",
      "Epoch 26/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3785\n",
      "Epoch 27/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3785\n",
      "Epoch 28/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3774\n",
      "Epoch 29/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3784\n",
      "Epoch 30/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8437 - loss: 0.3768\n",
      "Epoch 31/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3784\n",
      "Epoch 32/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3783\n",
      "Epoch 33/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.3777\n",
      "Epoch 34/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3783\n",
      "Epoch 35/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.3784\n",
      "Epoch 36/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3783\n",
      "Epoch 37/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.3797\n",
      "Epoch 38/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3787\n",
      "Epoch 39/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3779\n",
      "Epoch 40/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3784\n",
      "Epoch 41/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3782\n",
      "Epoch 42/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3779\n",
      "Epoch 43/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3781\n",
      "Epoch 44/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3774\n",
      "Epoch 45/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.3782\n",
      "Epoch 46/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3780\n",
      "Epoch 47/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3776\n",
      "Epoch 48/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3789\n",
      "Epoch 49/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8437 - loss: 0.3778\n",
      "Epoch 50/50\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.3772\n",
      "\u001b[1m6556/6556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 705us/step - accuracy: 0.8444 - loss: 0.3747\n",
      "Test Loss: 0.3735933005809784\n",
      "Test Accuracy: 0.8450245261192322\n"
     ]
    }
   ],
   "source": [
    "# Time boundary, OCT, Nov, Dec, Jan\n",
    "purchase_oct_nov_dec_jan = purchase[((purchase['PURCHASE_DATE'].dt.year == 2018) | (purchase['PURCHASE_DATE'].dt.year == 2019)) &\n",
    "                                    ((purchase['PURCHASE_DATE'].dt.month == 10) |\n",
    "                                     (purchase['PURCHASE_DATE'].dt.month == 11) |\n",
    "                                     (purchase['PURCHASE_DATE'].dt.month == 12) |\n",
    "                                     (purchase['PURCHASE_DATE'].dt.month == 1))]\n",
    "grouped_df_oct_nov_dec_jan = purchase_oct_nov_dec_jan.groupby('MAGIC_KEY') # Group by MAGIC_KEY\n",
    "features = feature_extraction(purchase_oct_nov_dec_jan,grouped_df_oct_nov_dec_jan,box)\n",
    "\n",
    "# Labelling \n",
    "features = Labelling_features(features,purchase, 2019, 2) # for February of 2019\n",
    "\n",
    "#defining elimentary things\n",
    "labels = features['labels'].to_numpy()\n",
    "features_pure = (features.drop(columns=['labels'])).to_numpy()\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_pure)\n",
    "num_node = 50\n",
    "\n",
    "# Model defining and setting previous weights\n",
    "model_oct_nov_dec_jan = define_model(features_scaled.shape[1], 1, num_node)\n",
    "model_oct_nov_dec_jan.set_weights(model_oct_nov_dec_weights)\n",
    "model_oct_nov_dec_jan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.2, random_state=42)\n",
    "hist_oct_nov_dec_jan = model_oct_nov_dec_jan.fit(X_train, y_train, epochs=50, batch_size=2048)\n",
    "test_loss, test_accuracy = model_oct_nov_dec_jan.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "model_oct_nov_dec_jan_weights = model_oct_nov_dec_jan.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming model is your TensorFlow model object\n",
    "\n",
    "model_oct_nov_dec_jan.save_weights('model.weights.h5')\n",
    "\n",
    "# model = define_model(features_scaled.shape[1], 1, num_node)\n",
    "# model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Feb test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/6 Extracting Bi-Weekly and Monthly Purchase Count...\n",
      "2/6 Extracting Average Time between purchase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monaf\\AppData\\Local\\Temp\\ipykernel_20948\\4279281223.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  avg_time_between_purchases = grouped_df.apply(calculate_avg_time_between_purchases)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/6 Extracting Days since last purchase...\n",
      "4/6 Extracting purchase_count and total_spent...\n",
      "5/6 Extracting total_milk_quantity & total_meat_quantity...\n",
      "6/6 Extracting num_purchases_first_15_days and num_purchases_last_15_days...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1274087, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = purchase.groupby('MAGIC_KEY') # Group by MAGIC_KEY\n",
    "features = feature_extraction(purchase,grouped_df,box)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59466, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the file for testing\n",
    "bought = pd.read_csv('feb_bought.csv', header=None, names=['magic key'])\n",
    "not_bought = pd.read_csv('feb_not_bought.csv', header=None, names=['magic key'])\n",
    "merged_key = pd.concat([bought, not_bought]).drop_duplicates()\n",
    "merged_key = merged_key.drop(merged_key.index[0])\n",
    "merged_key['labels'] = merged_key['magic key'].isin(bought['magic key']).astype(int)\n",
    "merged_key = merged_key.sort_values(by='magic key')\n",
    "merged_key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59466, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df_reset = features.reset_index() # Reset index of features DataFrame\n",
    "magic_keys = merged_key['magic key']\n",
    "filtered_features_df = features_df_reset[features_df_reset['MAGIC_KEY'].isin(magic_keys)]\n",
    "filtered_features_df = filtered_features_df.sort_values(by='MAGIC_KEY')\n",
    "filtered_features_df.set_index('MAGIC_KEY', inplace=True)\n",
    "# filtered_features_df = filtered_features_df.drop(columns=['Label'])\n",
    "filtered_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  70/1859\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 730us/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1859/1859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# suitable for neural networks\n",
    "X_test = scaler.transform(filtered_features_df)\n",
    "predictions = model_oct_nov_dec_jan.predict(X_test)\n",
    "y_pred = (predictions > 0.2).astype(int)\n",
    "y_true = merged_key['labels'].values\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8314835368109508"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bought = pd.read_csv('feb_bought.csv', header=None, names=['magic key'])\n",
    "not_bought = pd.read_csv('feb_not_bought.csv', header=None, names=['magic key'])\n",
    "merged_key = pd.concat([bought, not_bought]).drop_duplicates()\n",
    "merged_key = merged_key.drop(merged_key.index[0])\n",
    "# Create the 'labels' column\n",
    "merged_key['labels'] = merged_key['magic key'].isin(bought['magic key']).astype(int)\n",
    "# Create the 'labels' column based on whether 'magic key' is in either 'bought' or 'not_bought'\n",
    "# merged_key['labels'] = merged_key['magic key'].isin(bought['magic key']) | merged_key['magic key'].isin(not_bought['magic key'])\n",
    "merged_key = merged_key.sort_values(by='magic key')\n",
    "merged_key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this if dropping labels are necessary \n",
    "features_df_reset = features.reset_index() # Reset index of features DataFrame\n",
    "magic_keys = merged_key['magic key']\n",
    "filtered_features_df = features_df_reset[features_df_reset['MAGIC_KEY'].isin(magic_keys)]\n",
    "filtered_features_df = filtered_features_df.sort_values(by='MAGIC_KEY')\n",
    "filtered_features_df.set_index('MAGIC_KEY', inplace=True)\n",
    "filtered_features_df = filtered_features_df.drop(columns=['Label'])\n",
    "filtered_features_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suitable for random forrest without pca scaled\n",
    "X_test = scaler.transform(filtered_features_df)\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_true = merged_key['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df_reset = features.reset_index() # Reset index of features DataFrame\n",
    "magic_keys = merged_key['magic key']\n",
    "filtered_features_df = features_df_reset[features_df_reset['MAGIC_KEY'].isin(magic_keys)]\n",
    "filtered_features_df = filtered_features_df.sort_values(by='MAGIC_KEY')\n",
    "filtered_features_df.set_index('MAGIC_KEY', inplace=True)\n",
    "# filtered_features_df = filtered_features_df.drop(columns=['Label'])\n",
    "filtered_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suitable for neural networks\n",
    "X_test = scaler.transform(filtered_features_df)\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = (predictions > 0.5).astype(int)\n",
    "y_true = merged_key['labels'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suitable for pca scaled\n",
    "X_test = scaler.transform(filtered_features_df)\n",
    "X_test = pca.transform(X_test)\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_true = merged_key['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('Problem 1/sample submission 1.csv')\n",
    "problem = pd.read_csv('Problem 1/problem 1.csv')\n",
    "# features_main =  pd.read_csv('features.csv')\n",
    "# features_main.set_index('MAGIC_KEY', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop(columns=['Label'], inplace=True)\n",
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df = features.loc[problem['MAGIC_KEY']]\n",
    "extracted_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Biweekly_Purchase_Count</th>\n",
       "      <th>Monthly_Purchase_Count</th>\n",
       "      <th>Avg_Time_Between_Purchases</th>\n",
       "      <th>Days_Since_Last_Purchase</th>\n",
       "      <th>Purchase_Count</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Total_Milk_Quantity</th>\n",
       "      <th>Total_Meat_Quantity</th>\n",
       "      <th>Num_Purchases_First_15_Days</th>\n",
       "      <th>Num_Purchases_Last_15_Days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAGIC_KEY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28D5BB06356</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>45.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293BEAB4E98</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>72.12</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962EE8065C</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>31.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957BE29EA9</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>35.96</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28E351A0745</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>63.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28FB7C09776</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>75.92</td>\n",
       "      <td>48.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28E0E3B69BF</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28D343103A7</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>35.96</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290B1D6D5CB</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>29.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28FF193CB94</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>27.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58689 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Biweekly_Purchase_Count  Monthly_Purchase_Count  \\\n",
       "MAGIC_KEY                                                      \n",
       "28D5BB06356                 0.250000                     0.6   \n",
       "293BEAB4E98                 0.333333                     0.8   \n",
       "2962EE8065C                 0.166667                     0.4   \n",
       "2957BE29EA9                 0.166667                     0.4   \n",
       "28E351A0745                 0.333333                     0.8   \n",
       "...                              ...                     ...   \n",
       "28FB7C09776                 0.333333                     0.8   \n",
       "28E0E3B69BF                 0.166667                     0.4   \n",
       "28D343103A7                 0.166667                     0.4   \n",
       "290B1D6D5CB                 0.166667                     0.4   \n",
       "28FF193CB94                 0.166667                     0.4   \n",
       "\n",
       "             Avg_Time_Between_Purchases  Days_Since_Last_Purchase  \\\n",
       "MAGIC_KEY                                                           \n",
       "28D5BB06356                   32.500000                         2   \n",
       "293BEAB4E98                   41.333333                        20   \n",
       "2962EE8065C                   26.000000                        11   \n",
       "2957BE29EA9                   29.000000                        56   \n",
       "28E351A0745                   29.000000                        34   \n",
       "...                                 ...                       ...   \n",
       "28FB7C09776                   37.000000                         3   \n",
       "28E0E3B69BF                   46.000000                         0   \n",
       "28D343103A7                   24.000000                        23   \n",
       "290B1D6D5CB                   33.000000                        27   \n",
       "28FF193CB94                   60.000000                        13   \n",
       "\n",
       "             Purchase_Count  Total_Spent  Total_Milk_Quantity  \\\n",
       "MAGIC_KEY                                                       \n",
       "28D5BB06356               3        45.88                  0.0   \n",
       "293BEAB4E98               4        72.12                 58.0   \n",
       "2962EE8065C               2        31.92                  0.0   \n",
       "2957BE29EA9               2        35.96                 16.0   \n",
       "28E351A0745               4        63.84                  0.0   \n",
       "...                     ...          ...                  ...   \n",
       "28FB7C09776               4        75.92                 48.0   \n",
       "28E0E3B69BF               2        29.92                  0.0   \n",
       "28D343103A7               2        35.96                 20.0   \n",
       "290B1D6D5CB               2        29.92                  0.0   \n",
       "28FF193CB94               2        27.92                  0.0   \n",
       "\n",
       "             Total_Meat_Quantity  Num_Purchases_First_15_Days  \\\n",
       "MAGIC_KEY                                                       \n",
       "28D5BB06356                 10.1                          0.0   \n",
       "293BEAB4E98                  6.2                          4.0   \n",
       "2962EE8065C                  7.2                          0.0   \n",
       "2957BE29EA9                  4.4                          2.0   \n",
       "28E351A0745                 14.4                          0.0   \n",
       "...                          ...                          ...   \n",
       "28FB7C09776                  8.8                          1.0   \n",
       "28E0E3B69BF                  6.4                          1.0   \n",
       "28D343103A7                  5.0                          2.0   \n",
       "290B1D6D5CB                  6.5                          1.0   \n",
       "28FF193CB94                  4.9                          1.0   \n",
       "\n",
       "             Num_Purchases_Last_15_Days  \n",
       "MAGIC_KEY                                \n",
       "28D5BB06356                         3.0  \n",
       "293BEAB4E98                         0.0  \n",
       "2962EE8065C                         2.0  \n",
       "2957BE29EA9                         0.0  \n",
       "28E351A0745                         4.0  \n",
       "...                                 ...  \n",
       "28FB7C09776                         3.0  \n",
       "28E0E3B69BF                         1.0  \n",
       "28D343103A7                         0.0  \n",
       "290B1D6D5CB                         1.0  \n",
       "28FF193CB94                         1.0  \n",
       "\n",
       "[58689 rows x 10 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduced features \n",
    "extracted_features_df = features.loc[problem['MAGIC_KEY']]\n",
    "extracted_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/1835\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 18ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1835/1835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46729"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# suitable for neural networks\n",
    "X_sub = scaler.transform(extracted_features_df)\n",
    "predictions = model_oct_nov_dec_jan.predict(X_sub)\n",
    "y_sub = (predictions > 0.375).astype(int)  #  \n",
    "\n",
    "y_sub_labels = np.where(y_sub == 0, 'N', 'Y')\n",
    "y_sub_labels\n",
    "np.count_nonzero(y_sub_labels == 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58689, 1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sub_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.62139412837158"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(46729/58689)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y', 'N', ..., 'Y', 'Y', 'Y'], dtype='<U1')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_submit = np.squeeze(y_sub_labels)\n",
    "nn_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58689, 2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with MAGIC_KEY and PURCHASE columns\n",
    "submit = pd.DataFrame({'MAGIC_KEY': problem['MAGIC_KEY'], 'PURCHASE': nn_submit})\n",
    "submit.to_csv('submit_p1_v4_0.2.csv', index=False)\n",
    "submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'Y': 46729\n",
      "Number of 'N': 11960\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'nn_submit' is your numpy array\n",
    "# Count the occurrences of 'Y' and 'N'\n",
    "count_Y = np.count_nonzero(nn_submit == 'Y')\n",
    "count_N = np.count_nonzero(nn_submit == 'N')\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Number of 'Y': {count_Y}\")\n",
    "print(f\"Number of 'N': {count_N}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
